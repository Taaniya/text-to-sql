{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install datasets fuzzywuzzy dataset"
      ],
      "metadata": {
        "id": "02P5qd3AmUUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download `dataset.py` and `utils.py` from the repository by original paper authors [here](https://github.com/tzshi/squall/tree/main/model)"
      ],
      "metadata": {
        "id": "c6qeUznk1h5z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEVVbSPGk1UQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from dataset import load_dataset, em_process"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH = \"squall.json\""
      ],
      "metadata": {
        "id": "sIiQx92ymYdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load and explore SQUALL dataset"
      ],
      "metadata": {
        "id": "ShKMe5FRpv8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = load_dataset(DATASET_PATH)"
      ],
      "metadata": {
        "id": "RTDY0bxJmySw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0]"
      ],
      "metadata": {
        "id": "fEH_knW7myPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# alignment annotation of NLQ with SQL typed labels\n",
        "\n",
        "train_data[0]['nl_ralign']"
      ],
      "metadata": {
        "id": "InECF-wFmyJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenized NLQ (Natural Language question)\n",
        "\n",
        "train_data[0]['nl']"
      ],
      "metadata": {
        "id": "AvJBhBUemyGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# columns of table headers for this NLQ\n",
        "\n",
        "train_data[0]['columns']"
      ],
      "metadata": {
        "id": "EqYbJLRXmyCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0]['columns'][0]"
      ],
      "metadata": {
        "id": "JRh4Dwd1posD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transform into BIO format for NER task"
      ],
      "metadata": {
        "id": "xXRLUIwxp0vX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SAMPLE_SIZE = 50\n",
        "BIO_LABEL_MAP = {\n",
        "    \"None\": \"O\",\n",
        "    \"Keyword\": \"O\",\n",
        "    \"Column\": \"B-COLUMN\",\n",
        "    \"Literal\": \"B-LITERAL\"\n",
        "}"
      ],
      "metadata": {
        "id": "JIyK1tFspooZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Get tokenized nlq for 1st K rows"
      ],
      "metadata": {
        "id": "cwviXJoCqSFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlq_list = []\n",
        "for i in range(SAMPLE_SIZE):\n",
        "  nlq_list.append(train_data[i]['nl'])"
      ],
      "metadata": {
        "id": "ypfMinPzpolX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(nlq_list)"
      ],
      "metadata": {
        "id": "arJmmYQNpoiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlq_list[:5]"
      ],
      "metadata": {
        "id": "XuqP7U8ppoeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Get column list for the same samples above"
      ],
      "metadata": {
        "id": "kzLatyulql6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns_list = []\n",
        "for i in range(SAMPLE_SIZE):\n",
        "  col_list_per_nlq = []\n",
        "  for column_list in train_data[i]['columns']:\n",
        "    col_list_per_nlq.append(column_list[0])\n",
        "  columns_list.append(col_list_per_nlq)"
      ],
      "metadata": {
        "id": "7uQFTMmcpoaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(columns_list)"
      ],
      "metadata": {
        "id": "wKAUoDtcrME7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_list[8:15]"
      ],
      "metadata": {
        "id": "xDcTfrVMrMBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Get SQL type labels for each mention in tokenized NLQ"
      ],
      "metadata": {
        "id": "uR9M8qnSrZTL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sql_labels = []\n",
        "\n",
        "for i in range(SAMPLE_SIZE):\n",
        "  sql_label_per_token = []\n",
        "  for token in train_data[i]['nl_ralign']:\n",
        "    sql_label_per_token.append(BIO_LABEL_MAP[token[0]])\n",
        "  sql_labels.append(sql_label_per_token)"
      ],
      "metadata": {
        "id": "sFmmz_G7rL-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(sql_labels)"
      ],
      "metadata": {
        "id": "kgYUs5FKrL8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sql_labels[:5]"
      ],
      "metadata": {
        "id": "MDWcNjiFsAT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Get question IDs"
      ],
      "metadata": {
        "id": "tOU3dQgTrh2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qids = []\n",
        "for i in range(SAMPLE_SIZE):\n",
        "  qids.append(train_data[i]['nt'])"
      ],
      "metadata": {
        "id": "WsCv_65lsAQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(qids)"
      ],
      "metadata": {
        "id": "VTCA4k6NrL5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qids[:10]"
      ],
      "metadata": {
        "id": "S30xrJV3sP38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert sample to datasets instance for model training"
      ],
      "metadata": {
        "id": "-dCnMFhCrl7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "from datasets import load_dataset, Dataset, DatasetDict\n",
        "from datasets import Features, ClassLabel, Sequence, Value"
      ],
      "metadata": {
        "id": "Ofj6xK-zsR43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect above samples into a dictionary of features\n",
        "\n",
        "squall_dict = {\n",
        "    \"ner_tags\": sql_labels,\n",
        "    \"nl\": nlq_list,\n",
        "    \"nt\": qids,\n",
        "    \"columns\": columns_list\n",
        "}"
      ],
      "metadata": {
        "id": "nwf615jFsU5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define features - data type for each value for keys in above dictionary\n",
        "squall_features = Features({\n",
        " \"nl\": Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
        " \"columns\": Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
        " \"ner_tags\": Sequence(feature=ClassLabel(names=['O', 'B-COLUMN', 'I-COLUMN',\n",
        "                                                'B-LITERAL', 'I-LITERAL'],\n",
        "                                              id=None), length=-1, id=None),\n",
        " \"nt\": Value(dtype='string', id=None)\n",
        "})"
      ],
      "metadata": {
        "id": "E6p2RNAjsU1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "squall_dataset = Dataset.from_dict(\n",
        "    mapping=squall_dict,\n",
        "    features=squall_features,\n",
        "    split='train'\n",
        ")"
      ],
      "metadata": {
        "id": "pkeGaLRjsUy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "squall_dataset_df = DatasetDict()\n",
        "squall_dataset_df['train'] = squall_dataset"
      ],
      "metadata": {
        "id": "xd-ibAt-sUwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "squall_dataset_df"
      ],
      "metadata": {
        "id": "oyElaccRsUtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "squall_dataset_df['train'][0]"
      ],
      "metadata": {
        "id": "6na5L53xsUqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that the ner_tags are automatically converted to integers from their NER labels provided in the dictionary form. Defining the features with `Sequence` & `ClassLabel` instances enables the `dataset` to infer the data type & perform conversion wherever neccessary."
      ],
      "metadata": {
        "id": "m84k2q7lxDd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NER tags for a sample of 1st 5 cases (with NER tags)\n",
        "squall_dict['ner_tags'][:5]"
      ],
      "metadata": {
        "id": "03ms2owesUnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save this dataset to disk\n",
        "squall_dataset_df.save_to_disk(\"squall_sample_dataset\")"
      ],
      "metadata": {
        "id": "45CJdvEFsUkR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### References\n",
        "* SQUALL paper - https://arxiv.org/pdf/2010.11246\n",
        "* https://github.com/tzshi/squall\n",
        "* https://huggingface.co/docs/datasets/en/about_dataset_features\n",
        "* https://huggingface.co/docs/datasets/v2.19.0/en/package_reference/main_classes#datasets.Sequence\n",
        "* https://huggingface.co/docs/datasets/v2.19.0/en/package_reference/main_classes#datasets.Dataset"
      ],
      "metadata": {
        "id": "zzFKfShUmZDG"
      }
    }
  ]
}
